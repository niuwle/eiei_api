Date and Time: 02/02/2024 19.45.33
Directory Structure and Files in ./app:
./app/
├── __init__.py
├── config.py
├── controllers/
│   ├── __init__.py
│   ├── ai_communication.py
│   ├── message_processing.py
│   └── telegram_integration.py
├── database.py
├── database_operations.py
├── logging_config.py
├── models/
│   ├── __init__.py
│   ├── message.py
│   └── telegram_config.py
├── routers/
│   ├── message_controller.py
│   └── telegram_webhook.py
├── schemas.py
└── utils/
    ├── error_handler.py
    ├── process_audio.py
    └── process_photo.py

5 directories, 18 files

Details of Files:
___________
Start of file: ./app/routers/message_controller.py
# app/routers/message_controller.py
from fastapi import APIRouter, HTTPException
from app.schemas import TextMessage
from app.database import get_db
from app.database_operations import add_messages
from app.controllers.message_processing import process_queue
import asyncio
from app.utils.error_handler import handle_exception 
router = APIRouter()

@router.post("/receive-message")
async def receive_message(message: TextMessage):
    async with get_db() as db:
        try:
            added_message = await add_messages(db, message)
            await process_queue(added_message.chat_id, db)
            return {"pk_messages": added_message.pk_messages, "status": "Message saved successfully"}
        except Exception as e:
            handle_exception(e)End of file: ./app/routers/message_controller.py
___________
___________
Start of file: ./app/routers/telegram_webhook.py
import logging
import os
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks, Depends
from pydantic import BaseModel, Field
from typing import List
from sqlalchemy.ext.asyncio import AsyncSession
from app.schemas import TextMessage
from app.database import get_db
from app.database_operations import add_messages, get_bot_id_by_short_name, get_bot_token
from app.controllers.telegram_integration import send_telegram_message
from app.controllers.message_processing import process_queue
from app.utils.process_audio import transcribe_audio
from app.utils.process_photo import caption_photo
from app.utils.error_handler import handle_exception

logger = logging.getLogger(__name__)

class Voice(BaseModel):
    duration: int
    mime_type: str
    file_id: str
    file_size: int

class PhotoSize(BaseModel):
    file_id: str
    file_unique_id: str
    file_size: int
    width: int
    height: int

class Document(BaseModel):
    file_id: str
    file_unique_id: str
    file_size: int
    file_name: str
    mime_type: str
    thumb: PhotoSize = None

class Message(BaseModel):
    message_id: int
    from_: dict = Field(None, alias='from')
    chat: dict
    date: int
    text: str = None
    voice: Voice = None
    photo: List[PhotoSize] = None
    document: Document = None

class TelegramWebhookPayload(BaseModel):
    update_id: int
    message: Message

router = APIRouter()
SECRET_TOKEN = os.getenv("TELEGRAM_SECRET_TOKEN")

async def send_error_message_to_user(chat_id: int, bot_short_name: str, message: str):
    try:
        async with get_db() as db:
            bot_id = await get_bot_id_by_short_name(bot_short_name, db)
            bot_token = await get_bot_token(bot_id, db)
            await send_telegram_message(chat_id, message, bot_token)
    except Exception as e:
        logger.error(f"Failed to send error message to user due to: {e}")

async def process_message_type(message_data, chat_id, message_id, bot_id, bot_short_name, background_tasks, db, payload):
    message_type, process_task, text_prefix = None, None, ""
    task_params = {}

    if message_data.text:
        message_type = 'TEXT'
        text_prefix = message_data.text
        if message_data.text == "/start":
            predefined_response_text = "Hi I'm Tabatha! What about you?"
            await send_telegram_message(chat_id, predefined_response_text, await get_bot_token(bot_id, db))
            text_prefix = predefined_response_text
        else:
            process_task = process_queue
            task_params = {'chat_id': chat_id, 'db': db}  # common parameters for process_queue

    elif message_data.photo:
        message_type = 'PHOTO'
        process_task = caption_photo
        text_prefix = "[PROCESSING PHOTO]"
        task_params = {'bot_id': bot_id, 'chat_id': chat_id, 'db': db}  # common parameters for caption_photo

    elif message_data.document and message_data.document.mime_type.startswith("image/"):
        message_type = 'DOCUMENT'
        process_task = caption_photo
        text_prefix = "[PROCESSING DOCUMENT AS PHOTO]"
        task_params = {'bot_id': bot_id, 'chat_id': chat_id, 'db': db}  # common parameters for caption_photo

    elif message_data.voice:
        message_type = 'AUDIO'
        process_task = transcribe_audio
        text_prefix = "[TRANSCRIBING AUDIO]"
        task_params = {'bot_id': bot_id, 'chat_id': chat_id, 'db': db}  # common parameters for transcribe_audio

    if message_type:
        # Change payload.update_id to payload['update_id']
        messages_info = [
            {'message_data': TextMessage(chat_id=chat_id, user_id=0, bot_id=bot_id, message_text=text_prefix, message_id=message_id, channel="TELEGRAM", update_id=payload['update_id']), 'type': message_type, 'role': 'USER', 'is_processed': 'N'},
            {'message_data': TextMessage(chat_id=chat_id, user_id=0, bot_id=bot_id, message_text="[AI PLACEHOLDER]", message_id=message_id, channel="TELEGRAM", update_id=payload['update_id']), 'type': 'TEXT', 'role': 'ASSISTANT', 'is_processed': 'S'}
        ]

        added_messages = await add_messages(db, messages_info)
        if process_task and len(added_messages) > 1:
            # Add specific parameters based on the message type
            task_specific_params = {'message_pk': added_messages[0].pk_messages, 'ai_placeholder_pk': added_messages[1].pk_messages}
            if message_data.photo or message_data.voice or message_data.document:
                task_specific_params['file_id'] = message_data.photo[-1].file_id if message_data.photo else message_data.document.file_id if message_data.document else message_data.voice.file_id
            
            all_task_params = {**task_params, **task_specific_params}  # Merge common and specific parameters
            background_tasks.add_task(process_task, **all_task_params)

@router.post("/telegram-webhook/{token}/{bot_short_name}")
async def telegram_webhook(background_tasks: BackgroundTasks, request: Request, token: str, bot_short_name: str, db: AsyncSession = Depends(get_db)):
    chat_id = None # Declare chat_id outside the try block for wider scope
    if token != SECRET_TOKEN:
        raise HTTPException(status_code=403, detail="Invalid token")
    try:
        payload = await request.json() # Define payload here
        # Log the raw JSON payload
        logger.debug('Raw JSON Payload: %s', payload)

        payload_obj = TelegramWebhookPayload(**payload) # Parse JSON to Pydantic model
        # Log the parsed payload
        logger.debug('Parsed Payload: %s', payload_obj.dict())
        
        chat_id = payload_obj.message.chat['id']
        bot_id = await get_bot_id_by_short_name(bot_short_name, db)

        # Pass the Pydantic model, chat_id, message_id, bot_id, bot_short_name, background_tasks, and db to process_message_type
        await process_message_type(payload_obj.message, chat_id, payload_obj.message.message_id, bot_id, bot_short_name, background_tasks, db, payload)


    except Exception as e:
        logger.error(f"An error occurred while processing the request: {e}")
        if chat_id:
            # Use background_tasks to add an error handling task
            background_tasks.add_task(send_error_message_to_user, chat_id, bot_short_name, "Sorry, something went wrong. Please try again later.")
        raise HTTPException(status_code=500, detail="Internal Server Error")

    return {"status": "Message processed successfully"}
End of file: ./app/routers/telegram_webhook.py
___________
Binary File: ./app/.DS_Store
___________
Start of file: ./app/config.py
# app/config.py
import os
from dotenv import load_dotenv
load_dotenv()
SQLALCHEMY_DATABASE_URL = os.getenv("SQLALCHEMY_DATABASE_URL")
OPENROUTER_TOKEN = os.getenv("OPENROUTER_TOKEN")
TELEGRAM_SECRET_TOKEN = os.getenv("TELEGRAM_SECRET_TOKEN")
TELEGRAM_API_URL = os.getenv("TELEGRAM_API_URL")
OPENROUTER_MODEL = os.getenv("OPENROUTER_MODEL")
OPENROUTER_URL = os.getenv("OPENROUTER_URL", "https://openrouter.ai/api/v1/chat/completions")
ASSISTANT_PROMPT = os.getenv("ASSISTANT_PROMPT")
MONSTER_API_TOKEN = os.getenv("MONSTER_API_TOKEN")
HUGGINGFACE_API_TOKEN = os.getenv("HUGGINGFACE_API_TOKEN")End of file: ./app/config.py
___________
___________
Start of file: ./app/logging_config.py
import logging
from logging.config import dictConfig

def setup_logging():
    logging_config = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': {
            'standard': {
                'format': '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            },
        },
        'handlers': {
            'default': {
                'level': 'DEBUG',
                'formatter': 'standard',
                'class': 'logging.StreamHandler',
            },
            'sqlalchemy_engine': {
                'level': 'WARN',  # Set to WARN to reduce SQL logs
                'class': 'logging.StreamHandler',
                'formatter': 'standard',
            },
        },
        'loggers': {
            '': {
                'handlers': ['default'],
                'level': 'DEBUG',
                'propagate': True
            },
            'sqlalchemy.engine': {
                'handlers': ['sqlalchemy_engine'],
                'level': 'WARN',  # Adjust this level as needed
                'propagate': False
            },
        }
    }

    dictConfig(logging_config)
End of file: ./app/logging_config.py
___________
___________
Start of file: ./app/database.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
from sqlalchemy.orm import sessionmaker
from app.config import SQLALCHEMY_DATABASE_URL
from contextlib import asynccontextmanager

if not SQLALCHEMY_DATABASE_URL:
    raise ValueError("No SQLALCHEMY_DATABASE_URL set in environment")

engine = create_async_engine(SQLALCHEMY_DATABASE_URL, echo=True)

AsyncSessionLocal = sessionmaker(
    autocommit=False,
    autoflush=False,
    bind=engine,
    class_=AsyncSession
)


async def get_db():
    async with AsyncSessionLocal() as session:
        yield session
End of file: ./app/database.py
___________
Binary File: ./app/__init__.py
___________
Start of file: ./app/utils/process_audio.py
# app/routers/process_audio.py
import asyncio
import httpx
import logging
import os
import mimetypes
from app.database_operations import get_bot_token, mark_message_status, update_message_content
from app.config import TELEGRAM_API_URL, MONSTER_API_TOKEN
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional
import subprocess
import requests
from tempfile import NamedTemporaryFile
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks
from app.controllers.message_processing import process_queue

logger = logging.getLogger(__name__)
async def transcribe_audio(background_tasks: BackgroundTasks,  message_pk: int, ai_placeholder_pk: int, bot_id: int, chat_id: int, file_id: str, db: AsyncSession) -> Optional[str]:
    try:
        bot_token = await get_bot_token(bot_id=bot_id, db=db)
        file_url = f"{TELEGRAM_API_URL}{bot_token}/getFile?file_id={file_id}"

        async with httpx.AsyncClient() as client:
            file_response = await client.get(file_url)
            file_response.raise_for_status()

            file_path = file_response.json().get("result", {}).get("file_path", "")
            full_file_url = f"https://api.telegram.org/file/bot{bot_token}/{file_path}"

            logger.info(f"full_file_url {full_file_url}")

            # Convert audio file format
            converted_file_path = await convert_audio(full_file_url)  # Ensure this uses the same API as PL/SQL function

            # Prepare the file for upload
            file_name = os.path.basename(converted_file_path)
            files = {
                "file": (file_name, open(converted_file_path, "rb"), mimetypes.guess_type(converted_file_path)[0])
            }
            payload = {
                "diarize": "false",
                "do_sample": "true"
                #,"language": "en"
            }
            headers = {
                "accept": "application/json",
                "authorization": f"Bearer {MONSTER_API_TOKEN}"
            }

            # Send the transcription request
            transcription_response = await client.post(
                'https://api.monsterapi.ai/v1/generate/speech2text-v2',
                data=payload,
                files=files,
                headers=headers
            )
            response_json = transcription_response.json()
            logger.debug(f"Monster transcription_response JSON: {response_json}")


            transcription_response.raise_for_status()
            process_id = transcription_response.json().get('process_id', '')

            logger.info(f"Monster process_id {process_id}")

            # Check the status of the transcription in a loop
            max_attempts = 5
            attempt_count = 0
            transcribed_text = ''
            while attempt_count < max_attempts:
                await asyncio.sleep(3)  # Non-blocking sleep
                status_response = await client.get(f'https://api.monsterapi.ai/v1/status/{process_id}',
                headers=headers)
                status = status_response.json().get('status', '')

                if status == 'COMPLETED':
                    
                    response_json = status_response.json()
                    logger.debug(f"Monster response_json JSON: {response_json}")
                    transcribed_text = response_json.get('result', {}).get('text', '')
                    break

                attempt_count += 1
                await asyncio.sleep(3)  # Non-blocking sleep

            response_json = status_response.json()
            logger.info(f"Monster status transcription_response JSON: {response_json}")

            # Handle the response
            if not transcribed_text:
                error_message = "[Audio]: Transcription failed or incomplete"
                logger.error(error_message)
                await update_message_content(db, message_pk, error_message)
            else:
                logger.info(f"transcribed_text {transcribed_text}")
                await update_message_content(db, message_pk, transcribed_text)

            await mark_message_status(db, message_pk, 'N')
            os.remove(converted_file_path)
            background_tasks.add_task(process_queue, chat_id, ai_placeholder_pk.pk_messages, db)

    except Exception as e:
        logger.error(f"Error in transcribe_audio: {e}")
        await mark_message_status(db, message_pk, 'E')
        return None

async def convert_audio(file_url: str) -> str:
    try:
        response = requests.get(file_url)
        if response.status_code != 200:
            logger.error('Failed to download the file')
            return ''

        with NamedTemporaryFile(suffix='.oga', delete=True) as input_file:  # Changed to delete=True for cleanup
            input_file.write(response.content)
            input_file.flush()  # Ensure all data is written

            # Convert .oga to .ogg
            output_filename = input_file.name + '.ogg'
            subprocess.run(['ffmpeg', '-i', input_file.name, output_filename], check=True)

            return output_filename

    except subprocess.CalledProcessError as e:
        logger.error(f'Failed to convert the file: {e}')
    except Exception as e:
        logger.error(f'An error occurred during audio conversion: {e}')

    return ''
End of file: ./app/utils/process_audio.py
___________
___________
Start of file: ./app/utils/error_handler.py
# app/routers/error_handler.py
from fastapi import HTTPException
import logging

logger = logging.getLogger(__name__)

def handle_exception(e, status_code=500, detail=""):
    logger.error(f"Unexpected error: {str(e)}")
    raise HTTPException(status_code=status_code, detail=detail)
End of file: ./app/utils/error_handler.py
___________
___________
Start of file: ./app/utils/process_photo.py
# app/routers/process_photo.py
import asyncio
import httpx
import logging
import os
import mimetypes
from app.database_operations import get_bot_token, mark_message_status, update_message_content
from app.config import TELEGRAM_API_URL, HUGGINGFACE_API_TOKEN
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional
import subprocess
import requests
from tempfile import NamedTemporaryFile
from fastapi import APIRouter, HTTPException, Request, BackgroundTasks
from app.controllers.message_processing import process_queue

logger = logging.getLogger(__name__)

async def caption_photo(background_tasks: BackgroundTasks, message_pk: int, ai_placeholder_pk: int,  bot_id: int, chat_id: int, file_id: str, db: AsyncSession) -> Optional[str]:
    try:
        bot_token = await get_bot_token(bot_id=bot_id, db=db)
        file_url = f"{TELEGRAM_API_URL}{bot_token}/getFile?file_id={file_id}"

        async with httpx.AsyncClient() as client:
            file_response = await client.get(file_url)
            file_response.raise_for_status()

            file_path = file_response.json().get("result", {}).get("file_path", "")
            full_file_url = f"https://api.telegram.org/file/bot{bot_token}/{file_path}"

            # Download the photo file
            photo_response = await client.get(full_file_url)
            photo_response.raise_for_status()

            # Set up the headers and send the request to Hugging Face API
            headers = {
                "Authorization": f"Bearer {HUGGINGFACE_API_TOKEN}"
            }

            # Send the binary data of the photo directly in the request body
            caption_response = await client.post(
                'https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large',
                content=photo_response.content,
                headers=headers
            )

            caption_response.raise_for_status()
            caption_json = caption_response.json()
            caption_text = caption_json[0].get('generated_text', '[Photo]: Captioning failed or incomplete')

            # Handle the response
            logger.info(f"Caption text: {caption_text}")
            await update_message_content(db, message_pk, caption_text)
            await mark_message_status(db, message_pk, 'N')
            background_tasks.add_task(process_queue, chat_id, ai_placeholder_pk.pk_messages, db)

    except Exception as e:
        logger.error(f"Error in process_photo: {e}")
        await mark_message_status(db, message_pk, 'E')
        return None

End of file: ./app/utils/process_photo.py
___________
___________
Start of file: ./app/models/__init__.py
from sqlalchemy.ext.declarative import declarative_base
Base = declarative_base()
End of file: ./app/models/__init__.py
___________
___________
Start of file: ./app/models/message.py
#app/models/message.py
from sqlalchemy import Column, Integer, BigInteger, String, DateTime, func
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class tbl_msg(Base):
    __tablename__ = 'tbl_200_messages'

    pk_messages = Column(Integer, primary_key=True, index=True)  # Changed from id to pk_messages
    channel = Column(String(100))
    bot_id = Column(BigInteger, nullable=False) # NOT NULL constraint specified here
    chat_id = Column(BigInteger)
    user_id = Column(BigInteger)
    type = Column(String(100))
    role = Column(String(100))
    content_text = Column(String(4000))
    file_id = Column(String(4000))
    message_date = Column(DateTime) # This matches the TIMESTAMP in your SQL
    update_id = Column(BigInteger)
    message_id = Column(BigInteger)
    is_processed = Column(String(1))
    created_by = Column(String(1000))
    created_on = Column(DateTime, default=func.now()) # Default to the current timestamp
    updated_by = Column(String(1000))
    updated_on = Column(DateTime, default=func.now(), onupdate=func.now()) # Updated timestamp on update
End of file: ./app/models/message.py
___________
___________
Start of file: ./app/models/telegram_config.py
# app/models/telegram_config.py
from sqlalchemy import Column, Integer, String, DateTime
from . import Base

class TelegramConfig(Base):
    __tablename__ = 'tbl_100_telegram_config'

    pk_bot = Column(Integer, primary_key=True, index=True)
    bot_name = Column(String(100))
    bot_short_name = Column(String(100))
    bot_description = Column(String(4000))
    bot_token = Column(String(4000))
    bot_assistant_prompt = Column(String(4000))
    bot_pre_prompt = Column(String(4000))
    bot_temperature = Column(Integer)
    bot_presence_penalty = Column(Integer)
    bot_frequency_penalty = Column(Integer)
    bot_default_reply = Column(String(4000))
    created_by = Column(String(1000))
    created_on = Column(DateTime)
    updated_by = Column(String(1000))
    updated_on = Column(DateTime)
End of file: ./app/models/telegram_config.py
___________
___________
Start of file: ./app/schemas.py
#app/schemas.py
from pydantic import BaseModel
from datetime import datetime

class TextMessage(BaseModel):
    chat_id: int
    user_id: int
    bot_id: int
    message_text: str
    message_id: int
    channel: str
    update_id: int
End of file: ./app/schemas.py
___________
___________
Start of file: ./app/database_operations.py
from sqlalchemy.orm import Session
from app.models.message import tbl_msg
from app.models.telegram_config import TelegramConfig
from datetime import datetime
from sqlalchemy.future import select
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy.ext.asyncio import AsyncSession
from app.schemas import TextMessage
from typing import List, Union
import logging

logger = logging.getLogger(__name__)

async def get_bot_token(bot_id: int, db: AsyncSession) -> str:
    try:
        query = select(TelegramConfig.bot_token).where(TelegramConfig.pk_bot == bot_id)
        result = await db.execute(query)
        return result.scalar_one_or_none()
    except SQLAlchemyError as e:
        logger.error(f"Database error in get_bot_token: {e}")
        return ''

async def get_bot_id_by_short_name(bot_short_name: str, db: AsyncSession) -> int:
    try:
        query = select(TelegramConfig.pk_bot).where(TelegramConfig.bot_short_name == bot_short_name)
        result = await db.execute(query)
        return result.scalar_one_or_none()
    except SQLAlchemyError as e:
        logger.error(f"Database error in get_bot_id_by_short_name: {e}")
        return None


async def add_messages(db: AsyncSession, messages_info: List[dict]) -> List[tbl_msg]:
 
    new_messages = []
    for message_info in messages_info:
        message_data = message_info['message_data']
        role = message_info['role']  # Dynamic role assignment
        type = message_info.get('type', 'TEXT')  # Default type is 'TEXT'
        is_processed = message_info.get('is_processed', 'N')  # Default is_processed status
        
        new_message = tbl_msg(
            chat_id=message_data.chat_id,
            user_id=message_data.user_id,
            bot_id=message_data.bot_id,
            content_text=message_data.message_text,
            message_id=message_data.message_id,
            channel=message_data.channel,
            update_id=message_data.update_id,
            message_date=datetime.now(),
            type=type,
            is_processed=is_processed,
            role=role
        )
        db.add(new_message)
        new_messages.append(new_message)

    await db.commit()
    for new_message in new_messages:
        await db.refresh(new_message)

    logger.debug(f"Messages added: {[message.pk_messages for message in new_messages]}")
    return new_messages

async def update_message_content(db: AsyncSession, message_pk: int, new_content: str):
    try:
        query = select(tbl_msg).where(tbl_msg.pk_messages == message_pk)
        result = await db.execute(query)
        message = result.scalar_one_or_none()
        if message:
            message.content_text = new_content
            await db.commit()
            logger.info(f"Updated content_text for message with pk {message_pk}")
        else:
            logger.warning(f"No message found with pk {message_pk}")
    except SQLAlchemyError as e:
        logger.error(f"Database error in update_message_content: {e}")
        raise

async def mark_message_status(db: AsyncSession, message_pk: int, new_status: str):
    try:
        query = select(tbl_msg).where(tbl_msg.pk_messages == message_pk)
        result = await db.execute(query)
        message = result.scalar_one_or_none()
        if message:
            message.is_processed = new_status
            await db.commit()
            logger.info(f"Message with pk {message_pk} marked as {new_status}")
        else:
            logger.warning(f"No message found with pk {message_pk}")
    except SQLAlchemyError as e:
        logger.error(f"Database error in mark_message_status: {e}")
        raise
End of file: ./app/database_operations.py
___________
___________
Start of file: ./app/controllers/__init__.py
from fastapi import APIRouter
from app.routers.message_controller import router as message_router

router = APIRouter()

router.include_router(message_router)
End of file: ./app/controllers/__init__.py
___________
___________
Start of file: ./app/controllers/message_processing.py
# ./app/controllers/message_processing.py
import logging
from datetime import datetime
from sqlalchemy.ext.asyncio import AsyncSession
from app.database_operations import get_bot_token, add_messages, mark_message_status, update_message_content
from app.controllers.ai_communication import get_chat_completion
from app.controllers.telegram_integration import send_telegram_message
from app.models.message import tbl_msg
from app.models import message  # Ensure this is imported
from sqlalchemy.future import select
from app.schemas import TextMessage
import asyncio
import regex as re

from collections import deque
from math import ceil

logger = logging.getLogger(__name__)

async def process_queue(chat_id: int, message_pk: int, ai_placeholder_pk: int,  db: AsyncSession):
    try:
        timestamp = datetime.now()
        await asyncio.sleep(3)
        logger.info(f"Processing queue for chat_id {chat_id} as of {timestamp}")

        stmt = select(tbl_msg).where(tbl_msg.chat_id == chat_id, tbl_msg.is_processed == 'N').order_by(tbl_msg.message_date.desc())
        async with db:
            result = await db.execute(stmt)
            unprocessed_messages = result.scalars().all()

        logger.info(f"Unprocessed messages: {unprocessed_messages}") 

        logger.debug(f"Unprocessed messages: {unprocessed_messages}") # Debug statement

        if unprocessed_messages:
            logger.info(f"Comparing message_date {unprocessed_messages[0].message_date} and timestamp {timestamp}")

            if unprocessed_messages[0].message_date <= timestamp:
                await process_message(unprocessed_messages, db, chat_id, ai_placeholder_pk)
            else:
                # Skip processing as a new message arrived during the wait
                logger.info(f"Skipping processing: New message for chat_id {chat_id} arrived during wait.")
            
            
    except Exception as e:
        logger.error(f'Error processing queue: {e}')
        await db.rollback()
    finally:
        await db.close()


async def process_message(messages, db, chat_id, ai_placeholder_pk: int,):
    logger.debug(f"Messages to process: {messages}") # Debug statement

    # Mark all messages as processed once
    for message in messages:
        await mark_message_status(db, message.pk_messages, 'P')

    # Get chat completion only once
    try:
        response_text = await asyncio.wait_for(get_chat_completion(chat_id, messages[0].bot_id, db), timeout=10)
    except asyncio.TimeoutError:
        logger.error(f"get_chat_completion timed out for chat_id {chat_id}")
        response_text = None
        
    logger.debug(f"Chat completion response: {response_text}") # Debug statement

    if response_text:
        # Apply humanization to the response text
        humanized_response = humanize_response(response_text)
        bot_token = await get_bot_token(messages[0].bot_id, db)

        # Loop through each chunk and send it as a separate message
        for chunk in humanized_response:
            await send_telegram_message(chat_id, chunk, bot_token)

        # Use the updated add_message function to save the response
        # await add_message(db, response_message_data, type='TEXT', is_processed='Y', role='ASSISTANT')
        await update_message_content(db, ai_placeholder_pk, response_text)
        await mark_message_status(db, ai_placeholder_pk, 'Y')

        # Mark all messages as processed again
        for message in messages:
            await mark_message_status(db, message.pk_messages, 'Y')
    
    else:

        # Response was not getted so we mark for reprocesing later
        for message in messages:
            await mark_message_status(db, message.pk_messages, 'N')

    # Log the count of records processed
    logger.info(f"{len(messages)} messages processed for chat_id {chat_id}") 
    

def humanize_response(paragraph):

    paragraph = paragraph.replace('¡', '').replace('¿', '')
    # Define a pattern to match a period, question mark, or exclamation mark
    pattern = r'(?<=[.!?]) +'

    # Use regex to split the paragraph into records based on the defined pattern
    records = re.split(pattern, paragraph)

    # Filter out empty strings
    records = [rec for rec in records if rec.strip()]

    return records

End of file: ./app/controllers/message_processing.py
___________
___________
Start of file: ./app/controllers/telegram_integration.py
# ./app/controllers/telegram_integration.py
import httpx
import logging
from app.config import TELEGRAM_API_URL
import asyncio

logger = logging.getLogger(__name__)

async def send_telegram_message(chat_id: int, text: str, bot_token: str) -> bool:
    # Send 'typing' action
    await send_typing_action(chat_id, bot_token)

    # Calculate delay based on the length of the message
    typing_delay = calculate_typing_delay(text)
    await asyncio.sleep(typing_delay)

    # Send the actual message
    url = f'{TELEGRAM_API_URL}{bot_token}/sendMessage'
    payload = {"chat_id": chat_id, "text": text}

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload)
        response.raise_for_status()
        return True
    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP error sending Telegram message: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in send_telegram_message: {str(e)}")
    return False

async def send_typing_action(chat_id: int, bot_token: str) -> bool:
    url = f'{TELEGRAM_API_URL}{bot_token}/sendChatAction'
    payload = {"chat_id": chat_id, "action": "typing"}

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload)
        response.raise_for_status()
        return True
    except httpx.HTTPStatusError as e:
        logger.error(f"HTTP error sending typing action: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in send_typing_action: {str(e)}")
    return False


def calculate_typing_delay(message: str) -> float:
    average_typing_speed_per_minute = 200  # average words per minute (wpm)
    words = len(message.split())
    minutes_to_type = words / average_typing_speed_per_minute
    return max(0.5, minutes_to_type * 60)  # Minimum delay of 0.5 seconds
End of file: ./app/controllers/telegram_integration.py
___________
___________
Start of file: ./app/controllers/ai_communication.py
# ./app/controllers/ai_communication.py
from sqlalchemy.ext.asyncio import AsyncSession
import httpx
import logging
from app.models.message import tbl_msg
from typing import Optional
from app.config import OPENROUTER_TOKEN, OPENROUTER_MODEL, OPENROUTER_URL, ASSISTANT_PROMPT
from httpx import HTTPError
from sqlalchemy.future import select

# Create a logger
logger = logging.getLogger(__name__)

async def get_chat_completion(chat_id: int, bot_id: int, db: AsyncSession) -> Optional[str]:
    try:
        messages = await db.execute(select(tbl_msg).filter(tbl_msg.chat_id == chat_id, tbl_msg.bot_id == bot_id, tbl_msg.is_processed != 'S').order_by(tbl_msg.message_date))
        messages = messages.scalars().all()
        logger.info(f"Retrieved {len(messages)} messages for chat_id {chat_id} and bot_id {bot_id}")
        # Calculate initial payload size
        payload_size = len(str([{"role": "system", "content": ASSISTANT_PROMPT}] + [{"role": message.role.lower(), "content": message.content_text} for message in messages]))

        # Remove oldest messages if payload size exceeds 8k  characters
        while payload_size > 8 * 1024:
            oldest_message = messages.pop(0)
            payload_size -= len(str({"role": oldest_message.role.lower(), "content": oldest_message.content_text}))

        payload = {
            "model": OPENROUTER_MODEL,
            "max_tokens": 4024,
            "messages": [{"role": "system", "content": ASSISTANT_PROMPT}] + [{"role": message.role.lower(), "content": message.content_text} for message in messages]
        }

        logger.debug(f"Sending JSON payload to OpenRouter: {payload}")  # Log the sent JSON payload

        async def fetch_response():
            async with httpx.AsyncClient() as client:
                response = await client.post(OPENROUTER_URL, json=payload, headers={"Authorization": f"Bearer {OPENROUTER_TOKEN}"})
            return response.json()

        response_data = await fetch_response()
        logger.info(f"Received response from OpenRouter: {response_data}")  # Log the received response

        return response_data.get("choices", [{}])[0].get("message", {}).get("content", "")

    except HTTPError as e:
        logger.error(f"HTTP error in get_chat_completion: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error in get_chat_completion: {str(e)}")
        return None
End of file: ./app/controllers/ai_communication.py
___________
